# План реализации workflow для редактирования онтологии

**Дата:** 2025-12-31  
**Автор:** AI Assistant  
**Связанные задачи:** (будут созданы в project-development.json)  
**Связанное предложение:** [25-1231-ontology-editing-workflow-selection.md](../../docs-preliminary/25-1231-ontology-editing-workflow-selection.md)  
**Порядок выполнения:** A → B

---

## Контекст

В результате анализа различных вариантов работы с онтологией через внешние инструменты принято решение использовать файловый workflow с Protege Desktop. Процесс включает экспорт онтологии в файл, редактирование в Protege, и импорт обратно в приложение.

**Цель:** Реализовать поддержку файлового workflow для редактирования онтологии через Protege Desktop.

**Текущее состояние:**
- ✅ Endpoint `/ds/data?graph=urn:ontology&format=turtle` существует (экспорт работает)
- ✅ SPARQL Update endpoint работает
- ❌ Endpoint для импорта файла онтологии отсутствует
- ❌ Механизм блокировки редактирования отсутствует

---

## Структурный план

### Этап A: Реализация минимального варианта

#### A.1 Создание endpoint для упрощённого экспорта онтологии

**Статус:** ✅ Выполнено

- A.1.1 Добавить endpoint `GET /ds/ontology`
  - ✅ Возвращает онтологию из графа `urn:ontology` в формате Turtle
  - ✅ Простой URL без параметров (удобно для Protege `File → Open from URL`)
  - ✅ Content-Type: `text/turtle`
  - ✅ Файл: `SparqlController.java`
  - **Реализация:** Добавлен метод `getOntology()` в `SparqlController.java`, использует `sparqlService.getGraphData("urn:ontology", "TURTLE")`

- A.1.2 Тестирование endpoint
  - ✅ Проверка доступности: `curl http://localhost:8083/ds/ontology` - работает (HTTP 200)
  - ✅ Проверка формата ответа (Turtle) - Content-Type: `text/turtle`
  - ✅ Проверка корректности данных - данные совпадают с `/ds/data?graph=urn:ontology&format=turtle`
  - **Результат:** Endpoint работает корректно, возвращает онтологию в формате Turtle

---

#### A.2 Создание endpoint для импорта онтологии

**Статус:** ✅ Выполнено

- A.2.1 Добавить метод в `SparqlService.java` для замены данных в графе
  - ✅ Метод: `replaceGraphData(String graphUri, InputStream dataStream, String format)`
  - ✅ Начало транзакции WRITE
  - ✅ Удаление старых данных из графа (`model.removeAll()`)
  - ✅ Загрузка новых данных из InputStream (`RDFDataMgr.read()`)
  - ✅ Commit транзакции
  - ✅ Обработка ошибок (abort при ошибке)
  - ✅ Файл: `code/backend/src/main/java/io/github/bondalen/feont/service/SparqlService.java`
  - **Дополнительно:** Добавлен вспомогательный метод `parseFormat()` для преобразования формата строки в `Lang` для Apache Jena

- A.2.2 Добавить endpoint `POST /ds/ontology/import` в `SparqlController.java`
  - ✅ Content-Type: `multipart/form-data`
  - ✅ Параметры: `file` (MultipartFile), `format` (по умолчанию "turtle")
  - ✅ Парсинг файла (поддержка Turtle, RDF/XML, JSON-LD через `parseFormat()`)
  - ✅ Вызов `sparqlService.replaceGraphData()` для графа `urn:ontology`
  - ✅ Возврат результата (JSON с информацией о количестве загруженных триплетов)
  - ✅ Файл: `code/backend/src/main/java/io/github/bondalen/feont/controller/SparqlController.java`
  - **Реализация:** Использует `MultipartFile`, `ObjectMapper` для формирования JSON ответа

- A.2.3 Добавить зависимости для работы с MultipartFile (если отсутствуют)
  - ✅ Spring Boot Web уже включает поддержку multipart
  - ✅ Проверка конфигурации `spring.servlet.multipart` в `application.yml` - конфигурация по умолчанию достаточна (максимальный размер файла 1MB, можно увеличить при необходимости)

- A.2.4 Тестирование endpoint импорта
  - ✅ Загрузка тестового файла через curl: `curl -X POST -F "file=@/tmp/ontology-export.ttl" -F "format=turtle" http://localhost:8083/ds/ontology/import`
  - ✅ Проверка корректности загрузки данных - импорт успешен, загружено 15 триплетов
  - ✅ Проверка данных после импорта через `/ds/ontology` - данные корректно загружены
  - **Результат:** Endpoint работает корректно, возвращает JSON с информацией о количестве загруженных триплетов
  - Проверка замены данных в графе `urn:ontology`
  - Проверка обработки ошибок (неправильный формат файла)

---

#### A.3 Документирование workflow

**Статус:** ✅ Выполнено

- A.3.1 Создать документацию workflow для пользователей
  - ✅ Пошаговая инструкция процесса экспорта/импорта
  - ✅ Описание форматов файлов (Turtle, RDF/XML, JSON-LD, N3, N-Triples)
  - ✅ Рекомендации по работе с Protege Desktop
  - ✅ Процедура бэкапа данных TDB2
  - ✅ Примеры использования через curl и через Protege Desktop
  - ✅ Troubleshooting раздел с решением частых проблем
  - ✅ Файл: `docs/usage/ontology-editing-workflow.md` - создан

- A.3.2 Обновить документацию проекта
  - ✅ Добавлена информация о workflow в `project-docs.json`:
    - Обновлена секция `tools.ontology_editor` с информацией о workflow
    - Добавлены ссылки на endpoints экспорта/импорта
    - Добавлена ссылка на документацию workflow
  - ✅ Обновлён список endpoints в `backend.api_endpoints`:
    - Добавлены endpoints `/ds/ontology` (GET) и `/ds/ontology/import` (POST)
    - Добавлены описания всех основных endpoints API

---

#### A.4 Тестирование полного workflow

**Статус:** ⏳ Планируется

- A.4.1 Тестирование экспорта
  - ✅ Экспорт онтологии через `GET /ds/ontology` - успешно (33 строки, 1.6KB)
  - ✅ Сохранение файла - файл сохранён в `/tmp/ontology-test.ttl`
  - ✅ Проверка содержимого файла - файл содержит корректные RDF данные в формате Turtle:
    - Классы: Department, Employee
    - Свойства: name, worksIn
    - Все данные на русском языке с метками и комментариями

- A.4.2 Тестирование редактирования
  - Открытие файла в Protege Desktop
  - Внесение изменений (например, добавление класса)
  - Сохранение файла

- A.4.3 Тестирование импорта
  - Остановка приложения (для безопасности)
  - Бэкап TDB2
  - Загрузка изменённого файла через `POST /ds/ontology/import`
  - Запуск приложения
  - Проверка изменений в приложении (визуализация, SPARQL запросы)

- A.4.4 Проверка целостности данных
  - Проверка, что данные в графе `urn:ontology` корректны
  - Проверка, что другие графы (`urn:data`, `urn:shacl:shapes`) не затронуты
  - Выполнение тестовых SPARQL запросов

---

### Этап B: Реализация улучшенного варианта

#### B.1 Реализация механизма блокировки

**Статус:** ⏳ Планируется

- B.1.1 Добавить механизм блокировки в `SparqlService.java`
  - Переменная: `AtomicBoolean ontologyLocked`
  - Методы: `lockOntology()`, `unlockOntology()`, `isOntologyLocked()`
  - Файл: `code/backend/src/main/java/io/github/bondalen/feont/service/SparqlService.java`

- B.1.2 Добавить endpoints для блокировки в `SparqlController.java`
  - `POST /ds/ontology/lock` — установить блокировку
  - `POST /ds/ontology/unlock` — снять блокировку
  - `GET /ds/ontology/status` — получить статус блокировки (опционально)
  - Файл: `code/backend/src/main/java/io/github/bondalen/feont/controller/SparqlController.java`

- B.1.3 Добавить проверку блокировки в методы Update онтологии
  - Проверка в `executeUpdate()` — если запрос изменяет граф `urn:ontology`
  - Возврат ошибки, если онтология заблокирована
  - Проверка в `importOntology()` — блокировка должна быть установлена
  - Файл: `code/backend/src/main/java/io/github/bondalen/feont/service/SparqlService.java`

- B.1.4 Тестирование блокировки
  - Установка блокировки
  - Попытка SPARQL Update онтологии (должна быть заблокирована)
  - Попытка импорта без блокировки (должна быть заблокирована)
  - Снятие блокировки
  - Проверка, что после разблокировки операции работают

---

#### B.2 Добавление валидации загружаемой онтологии

**Статус:** ⏳ Планируется

- B.2.1 Реализовать синтаксическую валидацию RDF
  - Парсинг файла через Apache Jena
  - Проверка синтаксиса (Turtle, RDF/XML)
  - Обработка ошибок парсинга
  - Возврат понятных сообщений об ошибках
  - Файл: `code/backend/src/main/java/io/github/bondalen/feont/service/SparqlService.java`

- B.2.2 Добавить валидацию OWL (опционально)
  - Проверка синтаксиса OWL через Jena
  - Базовые проверки структуры (опционально)
  - Интеграция с reasoner для проверки согласованности (опционально, для будущего)

- B.2.3 Интеграция валидации в endpoint импорта
  - Валидация перед загрузкой данных в граф
  - Возврат ошибки валидации пользователю
  - Логирование ошибок валидации

- B.2.4 Тестирование валидации
  - Загрузка корректного файла (должна пройти)
  - Загрузка файла с синтаксическими ошибками (должна быть отклонена)
  - Загрузка файла некорректного формата (должна быть отклонена)
  - Проверка сообщений об ошибках

---

#### B.3 Сохранение истории изменений (опционально)

**Статус:** ⏳ Планируется (опционально)

- B.3.1 Реализовать сохранение предыдущей версии онтологии
  - Перед импортом сохранять текущую версию в граф `urn:ontology:history`
  - Добавить метаданные (дата, пользователь, опционально)
  - Метод в `SparqlService.java`: `saveOntologyHistory()`

- B.3.2 Добавить endpoint для просмотра истории (опционально)
  - `GET /ds/ontology/history` — список версий
  - `GET /ds/ontology/history/{version}` — конкретная версия

- B.3.3 Тестирование истории
  - Проверка сохранения версий при импорте
  - Проверка доступности истории через endpoint

---

#### B.4 Создание скриптов автоматизации (опционально)

**Статус:** ⏳ Планируется (опционально)

- B.4.1 Создать скрипт `scripts/export-ontology.sh`
  - Экспорт онтологии через curl
  - Сохранение с датой в имени файла
  - Вывод информации пользователю

- B.4.2 Создать скрипт `scripts/import-ontology.sh`
  - Принимает путь к файлу как аргумент
  - Автоматический бэкап TDB2
  - Загрузка файла через curl
  - Проверка результата

- B.4.3 Создать скрипт `scripts/backup-tdb2.sh`
  - Автоматический бэкап с датой в имени директории
  - Опционально: ограничение количества бэкапов (удаление старых)

- B.4.4 Документирование скриптов
  - README для скриптов
  - Примеры использования

---

#### B.5 Обновление документации

**Статус:** ⏳ Планируется

- B.5.1 Обновить документацию workflow
  - Добавить описание улучшенного варианта с блокировкой
  - Добавить инструкции по использованию скриптов (если созданы)
  - Добавить информацию о валидации

- B.5.2 Обновить API документацию
  - Добавить описание новых endpoints (lock, unlock, import)
  - Примеры запросов/ответов

---

#### B.6 Тестирование улучшенного workflow

**Статус:** ⏳ Планируется

- B.6.1 Тестирование с блокировкой
  - Экспорт → блокировка → редактирование → импорт → разблокировка
  - Проверка, что приложение работает в режиме чтения во время блокировки
  - Проверка, что Update заблокирован

- B.6.2 Тестирование валидации
  - Проверка валидации различных форматов файлов
  - Проверка обработки ошибок валидации

- B.6.3 Полное тестирование улучшенного workflow
  - Весь процесс от экспорта до импорта с использованием блокировки
  - Проверка целостности данных
  - Проверка истории (если реализована)

---

## Контрольные точки

### K1 — Минимальный вариант реализован (закрывает этап A)

**Критерии:**
- ✅ Endpoint `GET /ds/ontology` работает и возвращает онтологию в формате Turtle
- ✅ Endpoint `POST /ds/ontology/import` работает и корректно импортирует файл
- ✅ Полный workflow (экспорт → редактирование → импорт) протестирован
- ✅ Данные корректно сохраняются в графе `urn:ontology`
- ✅ Документация workflow создана

**Артефакты:**
- Обновлённый `SparqlController.java` с новыми endpoints
- Обновлённый `SparqlService.java` с методом `replaceGraphData()`
- Документация `docs/usage/ontology-editing-workflow.md`

---

### K2 — Улучшенный вариант реализован (закрывает этап B)

**Критерии:**
- ✅ Механизм блокировки работает
- ✅ Endpoints lock/unlock работают
- ✅ Валидация загружаемых файлов работает
- ✅ Полный улучшенный workflow протестирован
- ✅ Документация обновлена

**Артефакты:**
- Обновлённый `SparqlService.java` с блокировкой и валидацией
- Обновлённый `SparqlController.java` с endpoints блокировки
- Обновлённая документация
- Скрипты автоматизации (если созданы)

---

## Статус плана

- ⏳ **Этап A (A.0)** — Минимальный вариант — планируется
  - ⏳ A.1 Создание endpoint для экспорта — планируется
  - ⏳ A.2 Создание endpoint для импорта — планируется
  - ⏳ A.3 Документирование workflow — планируется
  - ⏳ A.4 Тестирование полного workflow — планируется
- ⏳ **Этап B (B.0)** — Улучшенный вариант — планируется
  - ⏳ B.1 Реализация механизма блокировки — планируется
  - ⏳ B.2 Добавление валидации — планируется
  - ⏳ B.3 Сохранение истории изменений — планируется (опционально)
  - ⏳ B.4 Создание скриптов автоматизации — планируется (опционально)
  - ⏳ B.5 Обновление документации — планируется
  - ⏳ B.6 Тестирование улучшенного workflow — планируется

---

## Предложения по следующим шагам

После завершения реализации:

1. **Тестирование на реальных данных**
   - Проверка workflow с реальной онтологией проекта
   - Проверка производительности при больших онтологиях

2. **Оптимизация (при необходимости)**
   - Оптимизация импорта для больших файлов
   - Кэширование экспортированной онтологии (опционально)

3. **Интеграция с frontend (опционально)**
   - Добавление UI для экспорта/импорта в веб-интерфейсе
   - Визуализация статуса блокировки (если реализована)

4. **Расширение функциональности (опционально)**
   - Поддержка экспорта/импорта других графов (например, `urn:data`)
   - Версионирование онтологии
   - Сравнение версий (diff)

---

## Связанные документы

- [project-docs.json](../../../project/project-docs.json) - документация проекта
- [project-development.json](../../project-development.json) - планирование задач
- [25-1231-ontology-editing-workflow-selection.md](../../docs-preliminary/25-1231-ontology-editing-workflow-selection.md) - документ с выбором workflow

---

## Примечания

- Минимальный вариант реализуется первым, затем улучшенный
- Опциональные пункты (B.3, B.4) могут быть реализованы при необходимости
- Механизм блокировки в улучшенном варианте позволяет приложению работать в режиме чтения во время редактирования онтологии
- Валидация важна для предотвращения загрузки некорректных данных
- Скрипты автоматизации упрощают процесс для пользователей

---

**Дата создания:** 2025-12-31  
**Статус:** План создан, готов к выполнению

